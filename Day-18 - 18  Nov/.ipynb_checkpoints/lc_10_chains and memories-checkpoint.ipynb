{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93b0a50f-f881-4ab3-b249-bbf4a6fad551",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "#### basic chain\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afde2ca-109a-4f7d-924a-6a2706115814",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_openai  import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f51d7c48-8e6b-4544-af31-2894b8ab3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "prompt = PromptTemplate.from_template(\"What is the capital of {country}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6831c297-d527-4834-83aa-58498aacdd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhupe\\AppData\\Local\\Temp\\ipykernel_14080\\2838644879.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm   = llm,\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM and chain\n",
    "llm   = ChatOpenAI()\n",
    "\n",
    "chain = LLMChain(llm   = llm, \n",
    "                 prompt= prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "191e20d1-e49f-4cba-9802-f490897c1851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'France', 'text': 'The capital of France is Paris.'}\n"
     ]
    }
   ],
   "source": [
    "# Run the chain\n",
    "result = chain.invoke({\"country\": \"France\"})\n",
    "print(result)  # Output should be \"Paris\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec3421-f625-4515-8f4b-e68bd71e0f97",
   "metadata": {},
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16577783-662a-403d-ad29-a5364c471eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a company that makes {product}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df452975-3247-4361-bd93-c8f62864e9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bcc470ef-7742-44d6-b6ae-36cf49d7ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"Nexon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87abde71-531c-4399-99ee-9d2582691e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'Nexon', 'text': 'Nexon Innovations'}\n"
     ]
    }
   ],
   "source": [
    "# Run the chain\n",
    "result = chain.invoke({\"product\": product})\n",
    "print(result)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0ecfbc-8b96-4295-84b9-7b9ed443f0ad",
   "metadata": {},
   "source": [
    "**Simple sequential chain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c94bd88-db64-4c46-a6be-9dd68cfe1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cf939c8-857d-4f92-807f-ea617cab3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0dbb8a46-1952-4041-aa52-9ec0d2e0ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d75ca22-665d-48b8-b4c8-07ae0ae1af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2379e17a-be7c-4e21-8f8b-8d76d5cc0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains =[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d0b3234-dab4-4237-b00b-5cca7f8bff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"fitbit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2fbd6d4-bc86-47f1-8bbd-be7679d3d5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mActiveLife Technologies\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mActiveLife Technologies is a leading provider of innovative health and wellness products, promoting an active lifestyle for improved well-being.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'fitbit',\n",
       " 'output': 'ActiveLife Technologies is a leading provider of innovative health and wellness products, promoting an active lifestyle for improved well-being.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.invoke(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3901d09c-f8ff-45e1-aada-e9655f03f8d2",
   "metadata": {},
   "source": [
    "**Exercise on Simple Sequential chain**\n",
    "\n",
    "- Text Processing Pipeline\n",
    "\n",
    "    - Remove punctuation from a text.\n",
    "    - Convert the text to lowercase.\n",
    "    - Count the number of words in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e1f7ba83-f964-48f0-8125-b429625ed282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "prompt_remove_punctuation = PromptTemplate(\n",
    "    input_variables = [\"text\"],\n",
    "    template        = \"Remove all punctuation from the following text:\\n{text}\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=prompt_remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "364c8927-adf1-422b-ab11-10f2333fc6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to lowercase\n",
    "prompt_to_lowercase = PromptTemplate(\n",
    "    input_variables = [\"text\"],\n",
    "    template        = \"Convert the following text to lowercase:\\n{text}\"\n",
    ")\n",
    "\n",
    "# Chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=prompt_to_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d292e0f3-99fc-4bda-8143-11924675982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the words\n",
    "prompt_count_words = PromptTemplate(\n",
    "    input_variables =[\"text\"],\n",
    "    template        = \"Count the number of words in the following text and return only the number:\\n{text}\"\n",
    ")\n",
    "\n",
    "# Chain 3\n",
    "chain_three = LLMChain(llm=llm, prompt=prompt_count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87687b53-c8c0-410a-bb52-7e20081dce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains =[chain_one, chain_two, chain_three],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73a8219a-1c79-4c2a-88c1-37f3dee5c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mModern humans arrived on the Indian subcontinent\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mmodern humans arrived on the indian subcontinent\u001b[0m\n",
      "\u001b[38;5;200m\u001b[1;3m7\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Modern humans arrived on the Indian subcontinent', 'output': '7'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Modern humans arrived on the Indian subcontinent'\n",
    "\n",
    "overall_simple_chain.invoke(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ce5eb5-7036-4338-98e4-233a2351d2ae",
   "metadata": {},
   "source": [
    "#### Sequential chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02c064f8-32fb-4ab7-9ff6-8432aa327b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.sequential import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1c1fe401-0222-4bff-8f4a-fe897855257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt templates\n",
    "prompt1 = PromptTemplate.from_template(\"What is the capital of {country}?\")\n",
    "prompt2 = PromptTemplate.from_template(\"Describe the main attractions in {city}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01f8c2c3-3841-467d-8c41-9808a9142270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cae729c3-fbcb-4a8c-bb7b-27d30ab9ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual chains with explicit output\n",
    "chain1 = LLMChain(llm       = llm, \n",
    "                  prompt    = prompt1, \n",
    "                  output_key=\"city\")               # Sets \"city\" as output for chain1\n",
    "\n",
    "chain2 = LLMChain(llm       = llm, \n",
    "                  prompt    = prompt2, \n",
    "                  output_key= \"city_description\")  # Sets \"city_description\" as output for chain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "51035d70-b930-42ee-8d82-bfafaae398f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the SequentialChain\n",
    "sequential_chain = SequentialChain(\n",
    "    chains           = [chain1, chain2],\n",
    "    input_variables  = [\"country\"],          # Input to the first chain\n",
    "    output_variables = [\"city_description\"]  # Output from the last chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cf8c79e1-f797-4827-b198-d3b23e4848f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo, the bustling capital of Japan, is a vibrant city with a plethora of attractions to offer visitors. Some of the main attractions in Tokyo include:\n",
      "\n",
      "1. Tokyo Tower: A symbol of the city, this iconic red and white tower offers panoramic views of Tokyo from its observation decks.\n",
      "\n",
      "2. Meiji Shrine: A peaceful oasis in the heart of the city, this Shinto shrine is dedicated to Emperor Meiji and Empress Shoken.\n",
      "\n",
      "3. Tsukiji Fish Market: One of the largest fish markets in the world, Tsukiji is a must-visit for seafood lovers looking to sample fresh sushi and seafood.\n",
      "\n",
      "4. Shibuya Crossing: Known as the busiest pedestrian crossing in the world, Shibuya Crossing is a must-see for visitors looking to experience the chaos and energy of Tokyo.\n",
      "\n",
      "5. Harajuku: A vibrant district known for its quirky fashion, Harajuku is a popular shopping destination with trendy boutiques, cafes, and street food stalls.\n",
      "\n",
      "6. Shinjuku Gyoen National Garden: A tranquil escape from the hustle and bustle of the city, this expansive garden features traditional Japanese landscapes, French-style gardens, and a greenhouse.\n",
      "\n",
      "7. Akihabara: Known as the electric town, Akihabara is a mecca for tech enthusiasts and anime fans, with countless electronics stores, manga shops, and arcades.\n",
      "\n",
      "8. Tokyo Disneyland and DisneySea: Located just outside the city, these two Disney theme parks offer a magical escape for visitors of all ages.\n",
      "\n",
      "9. Asakusa: Home to Senso-ji Temple, Tokyo's oldest temple, Asakusa is a historic district with traditional shops, restaurants, and a bustling street market.\n",
      "\n",
      "10. Roppongi Hills: A modern entertainment complex with shopping, dining, art galleries, and a panoramic observation deck offering views of the city skyline.\n"
     ]
    }
   ],
   "source": [
    "# Run the SequentialChain\n",
    "result = sequential_chain.invoke({\"country\": \"Japan\"})\n",
    "print(result[\"city_description\"])  # Should describe attractions in the capital city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feec4a1-fa1f-40b7-8e78-e0c52276b4b8",
   "metadata": {},
   "source": [
    "**Exercise on Sequential chain with multiple input variables**\n",
    "\n",
    "Design a Sequential Chain to analyze medical data from a patient's record. The chain should:\n",
    "\n",
    "- Take multiple inputs: age, blood_pressure, cholesterol_level, and smoking_status.\n",
    "\n",
    "    - Step 1: Assess the patient's `risk level` for heart disease based on the inputs (e.g., Low, Moderate, High).\n",
    "    - Step 2: Suggest `lifestyle changes` based on the risk level and smoking status.\n",
    "    - Step 3: Provide a `follow-up recommendation` based on the risk level and age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd3fb79d-315e-41ee-adc7-3137ed35d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Assess heart disease risk level\n",
    "prompt_risk_assessment = PromptTemplate(\n",
    "    input_variables = [\"age\", \"blood_pressure\", \"cholesterol_level\", \"smoking_status\"],\n",
    "    template        = (\n",
    "        \"Based on the following information:\\n\"\n",
    "        \"- Age: {age}\\n\"\n",
    "        \"- Blood Pressure: {blood_pressure}\\n\"\n",
    "        \"- Cholesterol Level: {cholesterol_level}\\n\"\n",
    "        \"- Smoking Status: {smoking_status}\\n\"\n",
    "        \"Assess the risk level for heart disease as Low, Moderate, or High.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61a993b3-86f1-4b0c-879b-d5c67600a7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Suggest lifestyle changes\n",
    "prompt_lifestyle_changes = PromptTemplate(\n",
    "    input_variables = [\"risk_level\", \"smoking_status\"],\n",
    "    template        = (\n",
    "        \"Given that the heart disease risk level is {risk_level} and the patient is a \"\n",
    "        \"{smoking_status} smoker, suggest lifestyle changes to improve health.\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "43c69c0d-05d6-4a4e-b7a8-157af4d482c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Provide follow-up recommendation\n",
    "prompt_follow_up = PromptTemplate(\n",
    "    input_variables = [\"risk_level\", \"age\"],\n",
    "    template = (\n",
    "        \"For a patient with a heart disease risk level of {risk_level} and age {age}, \"\n",
    "        \"provide a follow-up recommendation (e.g., frequency of doctor visits or specific tests).\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "838c5d8e-0f80-49d0-a762-5ee4a43bba41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual chains with explicit output\n",
    "chain1 = LLMChain(llm       = llm, \n",
    "                  prompt    = prompt_risk_assessment, \n",
    "                  output_key=\"risk_level\")              \n",
    "\n",
    "chain2 = LLMChain(llm       = llm, \n",
    "                  prompt    = prompt_lifestyle_changes, \n",
    "                  output_key= \"lifestyle_changes\")  \n",
    "\n",
    "chain3 = LLMChain(llm       = llm, \n",
    "                  prompt    = prompt_lifestyle_changes, \n",
    "                  output_key= \"recommendation\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87168d0e-a7bf-472e-8810-bce1648bd1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the SequentialChain\n",
    "sequential_chain = SequentialChain(\n",
    "    chains           = [chain1, chain2, chain3],\n",
    "    input_variables  = [\"age\", \"blood_pressure\", \"cholesterol_level\", \"smoking_status\"],         \n",
    "    output_variables = [\"recommendation\"]         # Output from the last chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be356354-04dd-4047-9454-8ce1db7f519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "patient_data = {\n",
    "    \"age\": 43,\n",
    "    \"blood_pressure\": \"130/100\",\n",
    "    \"cholesterol_level\": \"200 mg/dL\",\n",
    "    \"smoking_status\": 'current'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5e505cce-bd0c-4ced-b94b-15e840c30d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Quit smoking: Quitting smoking is one of the most important steps you can take to improve your heart health. Smoking damages your blood vessels, increases your blood pressure, and raises your risk of heart disease. Talk to your healthcare provider about resources and support to help you quit smoking.\n",
      "\n",
      "2. Eat a heart-healthy diet: Focus on eating a diet rich in fruits, vegetables, whole grains, lean proteins, and healthy fats. Limit your intake of saturated and trans fats, cholesterol, and sodium. Eating a balanced diet can help lower your cholesterol levels and blood pressure.\n",
      "\n",
      "3. Exercise regularly: Aim for at least 150 minutes of moderate-intensity exercise per week, such as brisk walking, cycling, or swimming. Regular physical activity can help lower your blood pressure, improve your cholesterol levels, and maintain a healthy weight.\n",
      "\n",
      "4. Manage stress: Chronic stress can contribute to high blood pressure and heart disease. Practice stress-reducing activities such as meditation, deep breathing exercises, yoga, or spending time in nature.\n",
      "\n",
      "5. Get regular check-ups: Make sure to see your healthcare provider regularly for check-ups and screenings to monitor your blood pressure, cholesterol levels, and overall heart health. They can provide guidance on managing your risk factors and making necessary lifestyle changes.\n"
     ]
    }
   ],
   "source": [
    "# Run the SequentialChain\n",
    "result = sequential_chain.invoke(patient_data)\n",
    "print(result[\"recommendation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87094abf-b7f5-4e75-b1e4-31d78c6ed832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
