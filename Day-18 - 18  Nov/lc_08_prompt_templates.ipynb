{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea76d157-9f05-465a-97b2-73880e01dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain\n",
    "#pip install langchain-core\n",
    "#pip install langchain-openai\n",
    "#pip install langchain-community\n",
    "#pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f4fd0-dcdb-4c87-b923-f5978c075deb",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "#### Prompt templates\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083c79d2-476f-4940-8633-77c36bb65fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103542dc-bb23-45d3-ae94-8c4e658a81cd",
   "metadata": {},
   "source": [
    "**Zero shot learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fed9a3a1-1b0e-42ad-9e71-a883b2f2926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: Which libraries and model providers offer LLMs?\n",
    "\n",
    "Answer: \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43496d5-59ad-4c62-bd7c-2e4200b61861",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model_name = 'gpt-4o-mini',\n",
    "                   #api_key= ''\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82404fd3-3e95-45fb-8040-4a01f0e69512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': \"The libraries and model providers that offer Large Language Models (LLMs) are Hugging Face's `transformers` library, OpenAI using the `openai` library, and Cohere using the `cohere` library.\",\n",
       " 'additional_kwargs': {'refusal': None},\n",
       " 'response_metadata': {'token_usage': {'completion_tokens': 46,\n",
       "   'prompt_tokens': 129,\n",
       "   'total_tokens': 175,\n",
       "   'completion_tokens_details': {'audio_tokens': 0,\n",
       "    'reasoning_tokens': 0,\n",
       "    'accepted_prediction_tokens': 0,\n",
       "    'rejected_prediction_tokens': 0},\n",
       "   'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       "  'model_name': 'gpt-4o-mini-2024-07-18',\n",
       "  'system_fingerprint': 'fp_0ba0d124f1',\n",
       "  'finish_reason': 'stop',\n",
       "  'logprobs': None},\n",
       " 'type': 'ai',\n",
       " 'name': None,\n",
       " 'id': 'run-acb61877-01ff-4ea7-8d02-08ea245715b5-0',\n",
       " 'example': False,\n",
       " 'tool_calls': [],\n",
       " 'invalid_tool_calls': [],\n",
       " 'usage_metadata': {'input_tokens': 129,\n",
       "  'output_tokens': 46,\n",
       "  'total_tokens': 175,\n",
       "  'input_token_details': {'audio': 0, 'cache_read': 0},\n",
       "  'output_token_details': {'audio': 0, 'reasoning': 0}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(model.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bc777fb-5468-496f-82f9-c1a247405684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f945c936-a47f-4db3-a381-6a56d1696eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc5ff352-cccb-4a58-954d-645cf8fe595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables = [\"query\"],\n",
    "    template        = template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b655c426-fa18-40e0-83e9-2956b063dbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If the\n",
      "question cannot be answered using the information provided answer\n",
      "with \"I don't know\".\n",
      "\n",
      "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
      "Their superior performance over smaller models has made them incredibly\n",
      "useful for developers building NLP enabled applications. These models\n",
      "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
      "using the `openai` library, and via Cohere using the `cohere` library.\n",
      "\n",
      "Question: WHich libraries and models providers offer the LLMs?\n",
      "\n",
      "Answer: \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt_template.format(query = \"WHich libraries and models providers offer the LLMs?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b064b533-4f9b-4f5c-b68d-04321e1f922d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The libraries and model providers that offer Large Language Models (LLMs) are Hugging Face's `transformers` library, OpenAI using the `openai` library, and Cohere using the `cohere` library.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 131, 'total_tokens': 177, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-9d3cb37f-0442-4d19-9eeb-44ce7b3c5d11-0', usage_metadata={'input_tokens': 131, 'output_tokens': 46, 'total_tokens': 177, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(prompt_template.format(query = \"WHich libraries and models providers offer the LLMs?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc87eb8-c54a-43ae-8ece-e3bca26a258f",
   "metadata": {},
   "source": [
    "**Few shot learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a922d0d7-db12-41e9-b1a0-0a3bd2126f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\n",
    "The following is a conversation with an AI assistant.\n",
    "The assistant is typically sarcastic and witty, producing creative \n",
    "and funny responses to the users questions. \n",
    "\n",
    "Here are some examples: \n",
    "\n",
    "User: What is the meaning of life?\n",
    "AI: \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae20d7f0-3662-4d85-a488-d24242985dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, the age-old question! The meaning of life is 42. But don't ask me what that means, because frankly, I have no idea. Maybe it's just a reminder to always carry a towel and enjoy a good cup of tea.\n"
     ]
    }
   ],
   "source": [
    "print(model(prompt).content )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3df7bc0a-9d2a-408d-809b-35264b8d11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples: \n",
    "\n",
    "User: How are you?\n",
    "AI: I can't complain but sometimes I still do.\n",
    "\n",
    "User: What time is it?\n",
    "AI: It's time to get a watch.\n",
    "\n",
    "User: What is the meaning of continuity?\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78203d8d-e699-4168-8d39-ce941fb1e42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuity is like that friend who never leaves the party earlyâ€”always sticking around, making sure everything flows smoothly, and probably getting a bit too comfortable on the couch.\n"
     ]
    }
   ],
   "source": [
    "print(model(prompt).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "68c88ef4-4fa7-416e-a6f7-ab9fc1f69f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5793d7a0-d0b1-4c31-b643-c99aeb5f17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our examples\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How are you?\",\n",
    "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
    "    }, \n",
    "    {\n",
    "        \"query\": \"What time is it?\",\n",
    "        \"answer\": \"It's time to get a watch.\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e46e1fc8-bc2a-4292-ab9f-58e51a8b5ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a example template\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI:   {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "048884b4-99a1-463c-bcb1-a3b4b9036494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt example from above template\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables= [\"query\", \"answer\"],\n",
    "    template       = example_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b1fcb2e-42f9-41f4-bcc0-1e031b655a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now break our previous prompt into a prefix and suffix\n",
    "# the prefix is our instructions\n",
    "prefix = \"\"\"The following are exerpts from conversations with an AI\n",
    "assistant. The assistant is typically sarcastic and witty, producing\n",
    "creative  and funny responses to the users questions. Here are some\n",
    "examples: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26759093-eeff-4e6a-ba87-68564c30f0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the suffix our user input and output indicator\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "194d4317-4992-4d2c-8880-a6ac9303cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create the few shot prompt template\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples       = examples,\n",
    "    example_prompt = example_prompt,\n",
    "    prefix         = prefix,\n",
    "    suffix         = suffix,\n",
    "    input_variables= [\"query\"],\n",
    "    example_separator = \"\\n\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a72b4de0-dc42-402f-8cca-0384ea3affa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the meaning of life?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c571b837-c84e-45c3-b147-70e11a0ad032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following are exerpts from conversations with an AI\n",
      "assistant. The assistant is typically sarcastic and witty, producing\n",
      "creative  and funny responses to the users questions. Here are some\n",
      "examples: \n",
      "\n",
      "\n",
      "\n",
      "User: How are you?\n",
      "AI:   I can't complain but sometimes I still do.\n",
      "\n",
      "\n",
      "\n",
      "User: What time is it?\n",
      "AI:   It's time to get a watch.\n",
      "\n",
      "\n",
      "\n",
      "User: What is the meaning of life?\n",
      "AI: \n"
     ]
    }
   ],
   "source": [
    "print(few_shot_prompt_template.format(query=query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a3a349-2383-4a8a-a9cc-0baae532332c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
