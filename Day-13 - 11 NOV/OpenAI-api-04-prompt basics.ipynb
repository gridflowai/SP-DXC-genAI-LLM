{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83020266-a956-4020-b8d8-d3c16fe66156",
   "metadata": {},
   "source": [
    "#### Prompt Engineering \n",
    "\n",
    "- Prompt - instructions to the LLM\n",
    "- Engg - best practices around the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7edcb1f-d894-4530-bb9c-5fc30e05a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e8f89d-25f0-4184-aa76-d949907d7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67665d6-fe4f-4baf-9739-a9585bc8d00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.53.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb7f07c-e0db-48db-b93b-808cfda0bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23f0c21-0414-4b1b-b221-4e9abe41ae25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb5834a-1417-41f2-b937-975cb467c526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79a980-e0d2-4430-883c-be9cf97827af",
   "metadata": {},
   "source": [
    "#### models in OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013db5ba-e16a-43e3-9f72-ebb02d5cfb02",
   "metadata": {},
   "source": [
    "OpenAI provides a variety of models, each suited for different use cases, ranging from text generation, code generation, to specific tasks like question answering, summarization, and more.\n",
    "\n",
    "| Model Type               | Description                                                                                       | Model ID               | Variants/Use Cases                                           |\n",
    "|--------------------------|---------------------------------------------------------------------------------------------------|------------------------|-------------------------------------------------------------|\n",
    "| **GPT-4 Models**         | The most advanced language model, designed for a wide range of tasks, including text completion and complex reasoning. | `gpt-4`                | Variants: `gpt-4`, `gpt-4-32k` (larger context window)     |\n",
    "| **GPT-3.5 Models**       | A slightly earlier version of the GPT-4 model, used for efficient and high-quality completions across various tasks. | `gpt-3.5-turbo`        |                                                             |\n",
    "| **Codex Models**         | Specialized for code generation tasks, including programming in multiple languages.              | `code-davinci-002`, `code-cushman-001` | Use cases: Autocomplete for code, bug fixes, code explanations. |\n",
    "| **Text-Davinci Models**  | One of the most capable models for text generation, document completion, and more.              | `text-davinci-003`     | Use cases: Writing, summarization, text generation.         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc7f88d-9c6e-4d42-80b3-bc30d302fa08",
   "metadata": {},
   "source": [
    "##### Key Properties of Models:\n",
    "- **Token Limit**: Defines how much input and output the model can handle in a single request. For example:\n",
    "  - GPT-4 has a context length limit of 8,192 tokens, and `gpt-4-32k` can handle up to 32,768 tokens.\n",
    "- **Training Data**: The models are trained on a mixture of publicly available and licensed datasets but have a knowledge cutoff (e.g., GPT-4 has a cutoff in September 2021).\n",
    "\n",
    "Each model has a balance of capability, efficiency, and cost, and you can select the right one depending on the task you need to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb6a09-bc2a-4282-a367-7c3c82532ae7",
   "metadata": {},
   "source": [
    "#### Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14385174-23ae-4048-982f-298cf7fbaf34",
   "metadata": {},
   "source": [
    "- OpenAI provides several API endpoints that enable developers to interact with their models for various tasks such as `text generation`, `conversation`, `code completion`, `embedding generation`, and more.\n",
    "\n",
    "- Each endpoint serves a different purpose and can be accessed via HTTP requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca819b-628a-488d-9690-ff3cccb190ed",
   "metadata": {},
   "source": [
    "1. Chat completion endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b24575-8b27-40f9-b2fe-0d69dab3c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d8bde42-1a87-41df-a420-c05a045befb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a55e49-69f3-4246-b26f-714e5ee3ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI (\n",
    "    #api_key = input_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc665858-55e3-4b44-85fa-61c859584ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL('https://api.openai.com/v1/')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5995adf0-d118-44ad-ae53-b2766aa4c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model    = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Can you summarize the key parameters available in the chat completion endpoint\"},\n",
    "    ],\n",
    "    #max_tokens = 170\n",
    "    temperature = 0.001\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d05439b-ca03-41c0-b20a-5704b77a94fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The key parameters available in the chat completion endpoint typically include:\n",
      "\n",
      "1. Chat ID: A unique identifier for the chat session.\n",
      "2. Completion Status: Indicates whether the chat session was completed successfully or not.\n",
      "3. Completion Time: The timestamp when the chat session was completed.\n",
      "4. Completion Message: Additional information or feedback provided upon completion of the chat session.\n",
      "5. User ID: The unique identifier for the user who participated in the chat session.\n",
      "6. Agent ID: The unique identifier for the agent who handled the chat session.\n",
      "7. Duration: The length of time the chat session lasted.\n",
      "8. Transcript: The text of the conversation between the user and the agent during the chat session.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9abfc4c6-0a0f-45f6-8b41-5d921f3c70ea",
   "metadata": {},
   "source": [
    "Sure! The key parameters available in the chat completion endpoint typically include:\n",
    "\n",
    "- chat_id: The unique identifier for the chat session\n",
    "- completion_status: The status of the chat completion, such as successful or failed\n",
    "- completion_time: The timestamp of when the chat was completed\n",
    "- user_id: The unique identifier for the user participating in the chat\n",
    "- chat_duration: The duration of the chat session\n",
    "- chat_actions: The actions taken during the chat session, such as messages sent or received, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072d556-d819-4bc5-b706-1fad091c81fa",
   "metadata": {},
   "source": [
    "#### Messsages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6682b4-3289-4de3-babc-99852f5d5562",
   "metadata": {},
   "source": [
    "In OpenAI's API for language models, messages are the fundamental building blocks of prompts. \n",
    "\n",
    "Each message typically consists of two main components: the `role` of the sender and the `content` of the message. \n",
    "\n",
    "| **Role**   | **Description**                                                                                                                                                 | **Example**                                                                                                                  |\n",
    "|------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------|\n",
    "| User       | Represents the end user or the application initiating the conversation. Sends input messages, asking questions or providing information for the model's response. | If a user asks, \"What is machine learning?\", the message is sent with the role of \"user\".                                  |\n",
    "| Assistant  | Represents the AI model's responses to the user’s queries. Generates replies based on the context and content of previous messages, aiming to be helpful and informative. | After the user asks about machine learning, the assistant might respond, \"Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data.\" |\n",
    "| System     | Provides initial instructions or context to the assistant to guide its behavior throughout the interaction. Typically used to set the tone, rules, or constraints of the assistant’s responses. | A system message might state, \"You are a friendly and informative assistant.\"                                              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8469fc11-1e7e-4c14-9b4a-8fbff9376ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a knowledgeable assistant.'},\n",
       " {'role': 'user', 'content': 'Can you tell me about neural networks?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Neural networks are a series of algorithms that mimic                                     the operations of a human brain to recognize relationships in a set of data.'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "  {\"role\": \"system\",    \"content\": \"You are a knowledgeable assistant.\"},\n",
    "  {\"role\": \"user\",      \"content\": \"Can you tell me about neural networks?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Neural networks are a series of algorithms that mimic \\\n",
    "                                    the operations of a human brain to recognize relationships in a set of data.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a0054a5-1b41-40c0-8955-4d80579f3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    #api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c52ea966-f8fe-4b2b-bede-5fc16f5909d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create (\n",
    "  model    = \"gpt-3.5-turbo\",\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts \\\n",
    "                                   with creative flair.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"Compose a poem that explains the concept of recursion in programming, \\\n",
    "                                   in max 50 words\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd16493e-9e8a-431d-a127-72a9bce3ea55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-ASO3lRy7P2q5tBLMA1Xvp4dAEteHK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In loops of code, a tale unfolds,\\nRecursive magic, a story that's told.\\nA function calls itself, a dance of delight,\\nCreating patterns with code, shining bright.\\nLike a mirror reflecting infinity's view,\\nRecursion in programming, a marvel anew.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1731329033, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=53, prompt_tokens=46, total_tokens=99, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=0, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64d4b6e7-7ed0-45c5-bd5f-2f43e6d70f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(response):\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9302bbee-e187-4258-bae9-6d3a92ce38f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In loops of code, a tale unfolds,\n",
      "Recursive magic, a story that's told.\n",
      "A function calls itself, a dance of delight,\n",
      "Creating patterns with code, shining bright.\n",
      "Like a mirror reflecting infinity's view,\n",
      "Recursion in programming, a marvel anew.\n"
     ]
    }
   ],
   "source": [
    "res= show_result(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5e54c-8ea2-47c0-9d1d-b6084993ae2d",
   "metadata": {},
   "source": [
    "**decipher the response output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3faae4a2-abf3-47ff-afe2-7a059cef939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef6d4ab8-29c7-41ba-8757-e8d5049303a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-ASNcfrWFAfdHINrIOppYwYrMquvnj',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'Sure! The key parameters available in the chat completion endpoint typically include:\\n\\n1. Chat ID: A unique identifier for the chat session.\\n2. Completion Status: Indicates whether the chat session was completed successfully or not.\\n3. Completion Time: The timestamp when the chat session was completed.\\n4. Completion Message: Additional information or feedback provided upon completion of the chat session.\\n5. User ID: The unique identifier for the user who participated in the chat session.\\n6. Agent ID: The unique identifier for the agent who handled the chat session.\\n7. Duration: The length of time the chat session lasted.\\n8. Transcript: The text of the conversation between the user and the agent during the chat session.',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1731327353,\n",
       " 'model': 'gpt-3.5-turbo-0125',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'completion_tokens': 142,\n",
       "  'prompt_tokens': 19,\n",
       "  'total_tokens': 161,\n",
       "  'completion_tokens_details': {'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09107901-0c4f-4c04-93ba-4eeaa377fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-ASNcfrWFAfdHINrIOppYwYrMquvnj\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Sure! The key parameters available in the chat completion endpoint typically include:\\n\\n1. Chat ID: A unique identifier for the chat session.\\n2. Completion Status: Indicates whether the chat session was completed successfully or not.\\n3. Completion Time: The timestamp when the chat session was completed.\\n4. Completion Message: Additional information or feedback provided upon completion of the chat session.\\n5. User ID: The unique identifier for the user who participated in the chat session.\\n6. Agent ID: The unique identifier for the agent who handled the chat session.\\n7. Duration: The length of time the chat session lasted.\\n8. Transcript: The text of the conversation between the user and the agent during the chat session.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1731327353,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 142,\n",
      "        \"prompt_tokens\": 19,\n",
      "        \"total_tokens\": 161,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_output = json.dumps(response.to_dict(), indent=4)\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e0e91-ad2b-431b-b2b8-7bd844411842",
   "metadata": {},
   "source": [
    "#### Attributes of ChatCompletion\n",
    "\n",
    "| Attribute          | Description                                                                                  |\n",
    "|--------------------|----------------------------------------------------------------------------------------------|\n",
    "| **id**             | A unique identifier for the completion request (e.g., `'chatcmpl-ABc5tNfn75ylhDfYoCrEBNlqk6xqO'`). |\n",
    "| **choices**        | A list of `Choice` objects representing the different responses generated by the model. In this case, there is one choice. |\n",
    "| **created**        | A timestamp indicating when the completion was created (e.g., `1727331405`).               |\n",
    "| **model**          | The model used to generate the completion (e.g., `'gpt-3.5-turbo-0125'`).                   |\n",
    "| **object**         | The type of object, which indicates it's a `chat.completion`.                               |\n",
    "| **usage**          | An object that details the token usage for the request and response, including:            |\n",
    "|                    | - **completion_tokens**: Number of tokens used in the completion (e.g., `45`).              |\n",
    "|                    | - **prompt_tokens**: Number of tokens used in the input prompt (e.g., `46`).               |\n",
    "|                    | - **total_tokens**: Total number of tokens used (e.g., `91`).                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd84a18-0e41-4d07-8398-fd87cf4f4c75",
   "metadata": {},
   "source": [
    "#### Exercise - 01\n",
    "\n",
    "- (extract pieces of info from the completion response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c281ac3-643b-44ef-a648-a5e1721c3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020?\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62a3d114-a094-4337-b119-122fa70b7046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Los Angeles Dodgers won the World Series in 2020. They defeated the Tampa Bay Rays in the World Series to win their first championship since 1988.\n"
     ]
    }
   ],
   "source": [
    "res = show_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de71480-5a38-4024-8f04-e801452ebe09",
   "metadata": {},
   "source": [
    "Qs : Extract the model name from the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d00603-231f-4d52-b378-57ec5c6d808f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb1a9c-6b35-408d-83a6-3c53b8dc3c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e6bef4-2273-42ad-b230-65b151fa6cd5",
   "metadata": {},
   "source": [
    "Qs : Extract the content of the assistant’s reply from the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da64221-a28b-43f0-ac15-869a41c0dfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cc6c1-26ea-433d-8327-b9de2f6135fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1afd248-0b66-4307-8bf3-4bd4957fe777",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020, 2021, 2022, 2023 ?\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b64dee-c7ab-41b4-9789-4359a525ee52",
   "metadata": {},
   "source": [
    "Qs : Create a dictionary of World Series winners by year from the assistant’s reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6c629-f4a5-487b-adf0-a429be51a5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b03c75db-b7c7-40a5-a547-22c73804b5bf",
   "metadata": {},
   "source": [
    "- **2020**: Los Angeles Dodgers\n",
    "- **2021**: Atlanta Braves\n",
    "- **2022**: Houston Astros\n",
    "- **2023**: Texas Rangers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9ec4da-bd31-4278-b2c7-ecebc12ff43a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
