{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83020266-a956-4020-b8d8-d3c16fe66156",
   "metadata": {},
   "source": [
    "#### Prompt Engineering \n",
    "\n",
    "- Prompt - instructions to the LLM\n",
    "- Engg - best practices around the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7edcb1f-d894-4530-bb9c-5fc30e05a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e8f89d-25f0-4184-aa76-d949907d7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67665d6-fe4f-4baf-9739-a9585bc8d00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.53.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb7f07c-e0db-48db-b93b-808cfda0bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23f0c21-0414-4b1b-b221-4e9abe41ae25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb5834a-1417-41f2-b937-975cb467c526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79a980-e0d2-4430-883c-be9cf97827af",
   "metadata": {},
   "source": [
    "#### models in OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013db5ba-e16a-43e3-9f72-ebb02d5cfb02",
   "metadata": {},
   "source": [
    "OpenAI provides a variety of models, each suited for different use cases, ranging from text generation, code generation, to specific tasks like question answering, summarization, and more.\n",
    "\n",
    "| Model Type               | Description                                                                                       | Model ID               | Variants/Use Cases                                           |\n",
    "|--------------------------|---------------------------------------------------------------------------------------------------|------------------------|-------------------------------------------------------------|\n",
    "| **GPT-4 Models**         | The most advanced language model, designed for a wide range of tasks, including text completion and complex reasoning. | `gpt-4`                | Variants: `gpt-4`, `gpt-4-32k` (larger context window)     |\n",
    "| **GPT-3.5 Models**       | A slightly earlier version of the GPT-4 model, used for efficient and high-quality completions across various tasks. | `gpt-3.5-turbo`        |                                                             |\n",
    "| **Codex Models**         | Specialized for code generation tasks, including programming in multiple languages.              | `code-davinci-002`, `code-cushman-001` | Use cases: Autocomplete for code, bug fixes, code explanations. |\n",
    "| **Text-Davinci Models**  | One of the most capable models for text generation, document completion, and more.              | `text-davinci-003`     | Use cases: Writing, summarization, text generation.         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc7f88d-9c6e-4d42-80b3-bc30d302fa08",
   "metadata": {},
   "source": [
    "##### Key Properties of Models:\n",
    "- **Token Limit**: Defines how much input and output the model can handle in a single request. For example:\n",
    "  - GPT-4 has a context length limit of 8,192 tokens, and `gpt-4-32k` can handle up to 32,768 tokens.\n",
    "- **Training Data**: The models are trained on a mixture of publicly available and licensed datasets but have a knowledge cutoff (e.g., GPT-4 has a cutoff in September 2021).\n",
    "\n",
    "Each model has a balance of capability, efficiency, and cost, and you can select the right one depending on the task you need to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb6a09-bc2a-4282-a367-7c3c82532ae7",
   "metadata": {},
   "source": [
    "#### Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14385174-23ae-4048-982f-298cf7fbaf34",
   "metadata": {},
   "source": [
    "- OpenAI provides several API endpoints that enable developers to interact with their models for various tasks such as `text generation`, `conversation`, `code completion`, `embedding generation`, and more.\n",
    "\n",
    "- Each endpoint serves a different purpose and can be accessed via HTTP requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca819b-628a-488d-9690-ff3cccb190ed",
   "metadata": {},
   "source": [
    "1. Chat completion endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b24575-8b27-40f9-b2fe-0d69dab3c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d8bde42-1a87-41df-a420-c05a045befb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a55e49-69f3-4246-b26f-714e5ee3ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI (\n",
    "    #api_key = input_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc665858-55e3-4b44-85fa-61c859584ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL('https://api.openai.com/v1/')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5995adf0-d118-44ad-ae53-b2766aa4c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model    = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Can you summarize the key parameters available in the chat completion endpoint\"},\n",
    "    ],\n",
    "    #max_tokens = 170\n",
    "    temperature = 0.001\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d05439b-ca03-41c0-b20a-5704b77a94fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The key parameters available in the chat completion endpoint typically include:\n",
      "\n",
      "1. Chat ID: A unique identifier for the chat session.\n",
      "2. Completion Status: Indicates whether the chat session was completed successfully or not.\n",
      "3. Completion Time: The timestamp when the chat session was completed.\n",
      "4. Completion Message: Additional information or feedback provided upon completion of the chat session.\n",
      "5. User ID: The unique identifier for the user who participated in the chat session.\n",
      "6. Agent ID: The unique identifier for the agent who handled the chat session.\n",
      "7. Duration: The length of time the chat session lasted.\n",
      "8. Transcript: The text of the conversation between the user and the agent during the chat session.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9abfc4c6-0a0f-45f6-8b41-5d921f3c70ea",
   "metadata": {},
   "source": [
    "Sure! The key parameters available in the chat completion endpoint typically include:\n",
    "\n",
    "- chat_id: The unique identifier for the chat session\n",
    "- completion_status: The status of the chat completion, such as successful or failed\n",
    "- completion_time: The timestamp of when the chat was completed\n",
    "- user_id: The unique identifier for the user participating in the chat\n",
    "- chat_duration: The duration of the chat session\n",
    "- chat_actions: The actions taken during the chat session, such as messages sent or received, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072d556-d819-4bc5-b706-1fad091c81fa",
   "metadata": {},
   "source": [
    "#### Messsages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6682b4-3289-4de3-babc-99852f5d5562",
   "metadata": {},
   "source": [
    "In OpenAI's API for language models, messages are the fundamental building blocks of prompts. \n",
    "\n",
    "Each message typically consists of two main components: the `role` of the sender and the `content` of the message. \n",
    "\n",
    "| **Role**   | **Description**                                                                                                                                                 | **Example**                                                                                                                  |\n",
    "|------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------|\n",
    "| User       | Represents the end user or the application initiating the conversation. Sends input messages, asking questions or providing information for the model's response. | If a user asks, \"What is machine learning?\", the message is sent with the role of \"user\".                                  |\n",
    "| Assistant  | Represents the AI model's responses to the user’s queries. Generates replies based on the context and content of previous messages, aiming to be helpful and informative. | After the user asks about machine learning, the assistant might respond, \"Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data.\" |\n",
    "| System     | Provides initial instructions or context to the assistant to guide its behavior throughout the interaction. Typically used to set the tone, rules, or constraints of the assistant’s responses. | A system message might state, \"You are a friendly and informative assistant.\"                                              |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8469fc11-1e7e-4c14-9b4a-8fbff9376ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a knowledgeable assistant.'},\n",
       " {'role': 'user', 'content': 'Can you tell me about neural networks?'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Neural networks are a series of algorithms that mimic                                     the operations of a human brain to recognize relationships in a set of data.'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "  {\"role\": \"system\",    \"content\": \"You are a knowledgeable assistant.\"},\n",
    "  {\"role\": \"user\",      \"content\": \"Can you tell me about neural networks?\"},\n",
    "  {\"role\": \"assistant\", \"content\": \"Neural networks are a series of algorithms that mimic \\\n",
    "                                    the operations of a human brain to recognize relationships in a set of data.\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a0054a5-1b41-40c0-8955-4d80579f3a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(\n",
    "    #api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c52ea966-f8fe-4b2b-bede-5fc16f5909d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create (\n",
    "  model    = \"gpt-3.5-turbo\",\n",
    "  messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts \\\n",
    "                                   with creative flair.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"Compose a poem that explains the concept of recursion in programming, \\\n",
    "                                   in max 50 words\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd16493e-9e8a-431d-a127-72a9bce3ea55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-ASO3lRy7P2q5tBLMA1Xvp4dAEteHK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In loops of code, a tale unfolds,\\nRecursive magic, a story that's told.\\nA function calls itself, a dance of delight,\\nCreating patterns with code, shining bright.\\nLike a mirror reflecting infinity's view,\\nRecursion in programming, a marvel anew.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1731329033, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=53, prompt_tokens=46, total_tokens=99, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=0, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64d4b6e7-7ed0-45c5-bd5f-2f43e6d70f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(response):\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9302bbee-e187-4258-bae9-6d3a92ce38f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In loops of code, a tale unfolds,\n",
      "Recursive magic, a story that's told.\n",
      "A function calls itself, a dance of delight,\n",
      "Creating patterns with code, shining bright.\n",
      "Like a mirror reflecting infinity's view,\n",
      "Recursion in programming, a marvel anew.\n"
     ]
    }
   ],
   "source": [
    "res= show_result(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5e54c-8ea2-47c0-9d1d-b6084993ae2d",
   "metadata": {},
   "source": [
    "**decipher the response output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3faae4a2-abf3-47ff-afe2-7a059cef939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef6d4ab8-29c7-41ba-8757-e8d5049303a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-ASNcfrWFAfdHINrIOppYwYrMquvnj',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'Sure! The key parameters available in the chat completion endpoint typically include:\\n\\n1. Chat ID: A unique identifier for the chat session.\\n2. Completion Status: Indicates whether the chat session was completed successfully or not.\\n3. Completion Time: The timestamp when the chat session was completed.\\n4. Completion Message: Additional information or feedback provided upon completion of the chat session.\\n5. User ID: The unique identifier for the user who participated in the chat session.\\n6. Agent ID: The unique identifier for the agent who handled the chat session.\\n7. Duration: The length of time the chat session lasted.\\n8. Transcript: The text of the conversation between the user and the agent during the chat session.',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant'}}],\n",
       " 'created': 1731327353,\n",
       " 'model': 'gpt-3.5-turbo-0125',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'completion_tokens': 142,\n",
       "  'prompt_tokens': 19,\n",
       "  'total_tokens': 161,\n",
       "  'completion_tokens_details': {'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'accepted_prediction_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09107901-0c4f-4c04-93ba-4eeaa377fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"chatcmpl-ASNcfrWFAfdHINrIOppYwYrMquvnj\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"finish_reason\": \"stop\",\n",
      "            \"index\": 0,\n",
      "            \"logprobs\": null,\n",
      "            \"message\": {\n",
      "                \"content\": \"Sure! The key parameters available in the chat completion endpoint typically include:\\n\\n1. Chat ID: A unique identifier for the chat session.\\n2. Completion Status: Indicates whether the chat session was completed successfully or not.\\n3. Completion Time: The timestamp when the chat session was completed.\\n4. Completion Message: Additional information or feedback provided upon completion of the chat session.\\n5. User ID: The unique identifier for the user who participated in the chat session.\\n6. Agent ID: The unique identifier for the agent who handled the chat session.\\n7. Duration: The length of time the chat session lasted.\\n8. Transcript: The text of the conversation between the user and the agent during the chat session.\",\n",
      "                \"refusal\": null,\n",
      "                \"role\": \"assistant\"\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"created\": 1731327353,\n",
      "    \"model\": \"gpt-3.5-turbo-0125\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"usage\": {\n",
      "        \"completion_tokens\": 142,\n",
      "        \"prompt_tokens\": 19,\n",
      "        \"total_tokens\": 161,\n",
      "        \"completion_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"reasoning_tokens\": 0,\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "        },\n",
      "        \"prompt_tokens_details\": {\n",
      "            \"audio_tokens\": 0,\n",
      "            \"cached_tokens\": 0\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "json_output = json.dumps(response.to_dict(), indent=4)\n",
    "print(json_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0e0e91-ad2b-431b-b2b8-7bd844411842",
   "metadata": {},
   "source": [
    "#### Attributes of ChatCompletion\n",
    "\n",
    "| Attribute          | Description                                                                                  |\n",
    "|--------------------|----------------------------------------------------------------------------------------------|\n",
    "| **id**             | A unique identifier for the completion request (e.g., `'chatcmpl-ABc5tNfn75ylhDfYoCrEBNlqk6xqO'`). |\n",
    "| **choices**        | A list of `Choice` objects representing the different responses generated by the model. In this case, there is one choice. |\n",
    "| **created**        | A timestamp indicating when the completion was created (e.g., `1727331405`).               |\n",
    "| **model**          | The model used to generate the completion (e.g., `'gpt-3.5-turbo-0125'`).                   |\n",
    "| **object**         | The type of object, which indicates it's a `chat.completion`.                               |\n",
    "| **usage**          | An object that details the token usage for the request and response, including:            |\n",
    "|                    | - **completion_tokens**: Number of tokens used in the completion (e.g., `45`).              |\n",
    "|                    | - **prompt_tokens**: Number of tokens used in the input prompt (e.g., `46`).               |\n",
    "|                    | - **total_tokens**: Total number of tokens used (e.g., `91`).                              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd84a18-0e41-4d07-8398-fd87cf4f4c75",
   "metadata": {},
   "source": [
    "#### Exercise - 01\n",
    "\n",
    "- (extract pieces of info from the completion response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c281ac3-643b-44ef-a648-a5e1721c3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020?\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "62a3d114-a094-4337-b119-122fa70b7046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Los Angeles Dodgers won the World Series in 2020. They defeated the Tampa Bay Rays to win their first World Series title since 1988.\n"
     ]
    }
   ],
   "source": [
    "res = show_result(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de71480-5a38-4024-8f04-e801452ebe09",
   "metadata": {},
   "source": [
    "Qs : Extract the model name from the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "65d00603-231f-4d52-b378-57ec5c6d808f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model used: gpt-3.5-turbo-0125\n"
     ]
    }
   ],
   "source": [
    "model_name = response.to_dict()['model']\n",
    "print(\"Model used:\", model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb1a9c-6b35-408d-83a6-3c53b8dc3c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2e6bef4-2273-42ad-b230-65b151fa6cd5",
   "metadata": {},
   "source": [
    "Qs : Extract the content of the assistant’s reply from the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2da64221-a28b-43f0-ac15-869a41c0dfd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant's reply: The Los Angeles Dodgers won the World Series in 2020. They defeated the Tampa Bay Rays to win their first World Series title since 1988.\n"
     ]
    }
   ],
   "source": [
    "assistant_reply = response.to_dict()['choices'][0]['message']['content']\n",
    "print(\"Assistant's reply:\", assistant_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2cc6c1-26ea-433d-8327-b9de2f6135fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1afd248-0b66-4307-8bf3-4bd4957fe777",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\",   \"content\": \"Who won the world series in 2020, 2021, 2022, 2023 ?\"},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b64dee-c7ab-41b4-9789-4359a525ee52",
   "metadata": {},
   "source": [
    "Qs : Create a dictionary of World Series winners by year from the assistant’s reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6de6c629-f4a5-487b-adf0-a429be51a5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The winners of the World Series for the years you specified are:\n",
      "\n",
      "- **2020**: Los Angeles Dodgers\n",
      "- **2021**: Atlanta Braves\n",
      "- **2022**: Houston Astros\n",
      "- **2023**: Texas Rangers\n",
      "\n",
      "If you need more information about any of these seasons, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "winners_by_year = response.to_dict()['choices'][0]['message']['content']\n",
    "print(winners_by_year)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b03c75db-b7c7-40a5-a547-22c73804b5bf",
   "metadata": {},
   "source": [
    "- **2020**: Los Angeles Dodgers\n",
    "- **2021**: Atlanta Braves\n",
    "- **2022**: Houston Astros\n",
    "- **2023**: Texas Rangers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2747ffc8-c2ac-4993-b072-2b92ad2e2f79",
   "metadata": {},
   "source": [
    "#### Reasoning capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "392a40f4-1631-4c12-b440-86025c148e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback = '''\n",
    "the trainer’s pace was slower than expected, and it seemed like he was copying code from his notebook \n",
    "without providing sufficient explanations on the \"what\" and \"why\" behind the actions. \n",
    "need for more in-depth explanations and context.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "575c9929-2978-479d-a860-8c452b09db43",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '''\n",
    "during the start of the training program, the learners were asked if they wished certain AI topics or lessons\n",
    "they would like the instructor to provide a quick recap or brush up and illustrations. Based of their feedback\n",
    "the instructor captured list of topics for the recap. The agreed assumption was that the learners are familiar with\n",
    "the topics but needed a quick refresher on them. The instructor provided walk thru on each of the topics with examples and illustration \n",
    "with python codes and gave them time of 5 mins on each topic if they had any qs or difficulties. During the entire 4 sessions the learners\n",
    "do not complaing about understanding the concepts, code, examples even after being polled explicitly for their repsonse.\n",
    "But a couple of them provide feedback at the end of the week to their manager, instead. leaving the instructor completely unaware.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31303262-a3e0-4f1d-bd66-aa964537d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model   = \"gpt-4o-mini\",\n",
    "    messages= [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant with abilities to interpret learners' feedback.\"},\n",
    "        {\"role\": \"user\",   \"content\": f\"Based on the {context}, assess if there are contradictions in the {feedback}. \\\n",
    "        Provide a clear explanation of your understanding of the feedback \\\n",
    "        Provide areas where learners could have helped the trainer in the recap sessions\"}\n",
    "    ],\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f54ed4b0-ba26-4681-9657-cc9b2d537831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the feedback provided, there are indeed contradictions in the learners' responses and their subsequent feedback to their manager. Here’s a breakdown of the situation:\n",
      "\n",
      "### Understanding of the Feedback\n",
      "\n",
      "1. **Initial Assumption**: The instructor assumed that the learners were familiar with the topics and only needed a quick refresher. This assumption was based on the learners' feedback at the beginning of the training program.\n",
      "\n",
      "2. **Instructor's Approach**: The instructor provided a walkthrough of each topic with examples and Python code, allowing time for questions. The fact that learners did not complain during the sessions suggests that they were either not fully engaged or did not feel comfortable voicing their concerns in that setting.\n",
      "\n",
      "3. **Contradictory Feedback**: Despite the lack of complaints during the sessions, the feedback to the manager indicated that the pace was slower than expected and that the instructor was merely copying code without sufficient explanations. This suggests that while learners may have felt they understood the material at a surface level, they were actually seeking deeper insights into the concepts.\n",
      "\n",
      "4. **Need for In-Depth Explanations**: The feedback highlights a desire for more context and understanding of the \"what\" and \"why\" behind the code and concepts being taught. This indicates that learners were looking for a more comprehensive understanding rather than just a recap.\n",
      "\n",
      "### Areas Where Learners Could Have Helped the Trainer\n",
      "\n",
      "1. **Active Participation**: Learners could have been more vocal during the sessions if they felt the pace was too slow or if they needed more detailed explanations. Asking questions or providing feedback in real-time could have helped the instructor adjust his approach.\n",
      "\n",
      "2. **Feedback Mechanism**: Establishing a more immediate feedback mechanism, such as anonymous polls or feedback forms after each session, could have encouraged learners to express their concerns without fear of judgment.\n",
      "\n",
      "3. **Clarifying Expectations**: At the beginning of the recap sessions, learners could have clarified their expectations regarding the depth of explanations they were seeking. This would have helped the instructor tailor his content more effectively.\n",
      "\n",
      "4. **Engagement in Discussions**: Encouraging discussions among peers could have provided insights into common areas of confusion or interest, allowing the instructor to address these points more thoroughly.\n",
      "\n",
      "5. **Providing Examples of Desired Depth**: Learners could have shared specific examples of topics or concepts where they felt more depth was needed, guiding the instructor on how to enhance the sessions.\n",
      "\n",
      "In summary, while the instructor aimed to provide a quick refresher based on the learners' initial feedback, the lack of real-time communication and engagement during the sessions led to a disconnect between the learners' needs and the instructor's delivery. Encouraging more active participation and feedback could have improved the overall learning experience.\n"
     ]
    }
   ],
   "source": [
    "print(response.to_dict()['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7b158-4f4d-4389-82ef-471b694d970f",
   "metadata": {},
   "source": [
    "#### Language translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2866bef8-6c37-4be8-8597-00ccdf9954bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create (\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex \\\n",
    "                                    programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\",   \"content\": \"Compose a poem that explains the \\\n",
    "                                   concept of recursion in programming, \\\n",
    "                                   in max 50 words\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "49d7a499-50ec-4a19-837b-73bab652fb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-ASObHrKaU95q4s0ng165WijxwghRy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='In the world of code, recursion glows,\\nA dance of functions, it bestows.\\nA loop within itself, a magical twist,\\nRepeating tasks with a recursive twist.\\nLike a mirror reflecting its own light,\\nRecursion calls itself, infinite might.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1731331111, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=52, prompt_tokens=47, total_tokens=99, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=0, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d6ea4d32-6253-4706-94d9-9947f8a68109",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello, how are you?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2aed54b3-310a-4bb2-9089-6777f44dd827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-ASOdbIRwOv655uVBnsv3aBX0qnQRL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The translation of \"Hello, how are you?\" in Bengali is \"হ্যালো, তুমি কেমন আছ?\"', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1731331255, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=42, prompt_tokens=31, total_tokens=73, completion_tokens_details=CompletionTokensDetails(audio_tokens=0, reasoning_tokens=0, accepted_prediction_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = client.chat.completions.create (\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant, on language translation\"},\n",
    "    {\"role\": \"user\",   \"content\": f\"Convert the given {text} in bangla\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff635d-d5f7-4f67-93e3-2ea0c1620e12",
   "metadata": {},
   "source": [
    "#### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "03b26a63-72b6-40e7-a518-52d414d530d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEG'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "                  model=\"gpt-3.5-turbo\",\n",
    "                  messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a NLP expert\"},\n",
    "                    {\"role\": \"user\",   \"content\": f\"Perform sentiment analysis of given text : {feedback} your answer should be either POS, NEG or DONT KNOW. No further explanation needed\"\n",
    "                    \n",
    "                    }\n",
    "                  ]\n",
    ")\n",
    "\n",
    "sentiment = response.choices[0].message.content.replace(\"\\n\", \" \")\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4becc1e-f168-48f7-a019-8bd0bbfb7e6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
