{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83020266-a956-4020-b8d8-d3c16fe66156",
   "metadata": {},
   "source": [
    "#### Prompt Engineering \n",
    "\n",
    "- Prompt - instructions to the LLM\n",
    "- Engg - best practices around the prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7edcb1f-d894-4530-bb9c-5fc30e05a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09e8f89d-25f0-4184-aa76-d949907d7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c67665d6-fe4f-4baf-9739-a9585bc8d00c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.53.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb7f07c-e0db-48db-b93b-808cfda0bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy \n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c23f0c21-0414-4b1b-b221-4e9abe41ae25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb5834a-1417-41f2-b937-975cb467c526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a79a980-e0d2-4430-883c-be9cf97827af",
   "metadata": {},
   "source": [
    "#### models in OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013db5ba-e16a-43e3-9f72-ebb02d5cfb02",
   "metadata": {},
   "source": [
    "OpenAI provides a variety of models, each suited for different use cases, ranging from text generation, code generation, to specific tasks like question answering, summarization, and more.\n",
    "\n",
    "| Model Type               | Description                                                                                       | Model ID               | Variants/Use Cases                                           |\n",
    "|--------------------------|---------------------------------------------------------------------------------------------------|------------------------|-------------------------------------------------------------|\n",
    "| **GPT-4 Models**         | The most advanced language model, designed for a wide range of tasks, including text completion and complex reasoning. | `gpt-4`                | Variants: `gpt-4`, `gpt-4-32k` (larger context window)     |\n",
    "| **GPT-3.5 Models**       | A slightly earlier version of the GPT-4 model, used for efficient and high-quality completions across various tasks. | `gpt-3.5-turbo`        |                                                             |\n",
    "| **Codex Models**         | Specialized for code generation tasks, including programming in multiple languages.              | `code-davinci-002`, `code-cushman-001` | Use cases: Autocomplete for code, bug fixes, code explanations. |\n",
    "| **Text-Davinci Models**  | One of the most capable models for text generation, document completion, and more.              | `text-davinci-003`     | Use cases: Writing, summarization, text generation.         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc7f88d-9c6e-4d42-80b3-bc30d302fa08",
   "metadata": {},
   "source": [
    "##### Key Properties of Models:\n",
    "- **Token Limit**: Defines how much input and output the model can handle in a single request. For example:\n",
    "  - GPT-4 has a context length limit of 8,192 tokens, and `gpt-4-32k` can handle up to 32,768 tokens.\n",
    "- **Training Data**: The models are trained on a mixture of publicly available and licensed datasets but have a knowledge cutoff (e.g., GPT-4 has a cutoff in September 2021).\n",
    "\n",
    "Each model has a balance of capability, efficiency, and cost, and you can select the right one depending on the task you need to perform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fb6a09-bc2a-4282-a367-7c3c82532ae7",
   "metadata": {},
   "source": [
    "#### Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14385174-23ae-4048-982f-298cf7fbaf34",
   "metadata": {},
   "source": [
    "- OpenAI provides several API endpoints that enable developers to interact with their models for various tasks such as `text generation`, `conversation`, `code completion`, `embedding generation`, and more.\n",
    "\n",
    "- Each endpoint serves a different purpose and can be accessed via HTTP requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca819b-628a-488d-9690-ff3cccb190ed",
   "metadata": {},
   "source": [
    "1. Chat completion endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b24575-8b27-40f9-b2fe-0d69dab3c033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d8bde42-1a87-41df-a420-c05a045befb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_api_key = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6a55e49-69f3-4246-b26f-714e5ee3ac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI (\n",
    "    #api_key = input_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc665858-55e3-4b44-85fa-61c859584ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "URL('https://api.openai.com/v1/')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5995adf0-d118-44ad-ae53-b2766aa4c643",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model    = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": \"Can you summarize the key parameters available in the chat completion endpoint\"},\n",
    "    ],\n",
    "    #max_tokens = 170\n",
    "    temperature = 0.001\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5d05439b-ca03-41c0-b20a-5704b77a94fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The key parameters available in the chat completion endpoint typically include:\n",
      "\n",
      "1. Chat ID: A unique identifier for the chat session.\n",
      "2. Completion Status: Indicates whether the chat session was completed successfully or not.\n",
      "3. Completion Time: The timestamp when the chat session was completed.\n",
      "4. Completion Message: Additional information or feedback provided upon completion of the chat session.\n",
      "5. User ID: The unique identifier for the user who participated in the chat session.\n",
      "6. Agent ID: The unique identifier for the agent who handled the chat session.\n",
      "7. Duration: The length of time the chat session lasted.\n",
      "8. Transcript: The text of the conversation between the user and the agent during the chat session.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9abfc4c6-0a0f-45f6-8b41-5d921f3c70ea",
   "metadata": {},
   "source": [
    "Sure! The key parameters available in the chat completion endpoint typically include:\n",
    "\n",
    "- chat_id: The unique identifier for the chat session\n",
    "- completion_status: The status of the chat completion, such as successful or failed\n",
    "- completion_time: The timestamp of when the chat was completed\n",
    "- user_id: The unique identifier for the user participating in the chat\n",
    "- chat_duration: The duration of the chat session\n",
    "- chat_actions: The actions taken during the chat session, such as messages sent or received, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ddc92-2721-4b52-b8d9-d77a3913cfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
